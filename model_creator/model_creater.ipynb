{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.system(\"rm -r logs\")\n",
    "import tensorflow as tf\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = '/home/winsoul/disk/fMRI/data/separatedData/mixedData/stimulationExceptStatic/tfrecords/train.tfrecords'\n",
    "testPath = '/home/winsoul/disk/fMRI/data/separatedData/mixedData/stimulationExceptStatic/tfrecords/test.tfrecords'\n",
    "valPath = '/home/winsoul/disk/fMRI/data/separatedData/mixedData/stimulationExceptStatic/tfrecords/val.tfrecords'\n",
    "model_path = '/home/winsoul/disk/fMRI/HEATMAP/ComputerDesign/model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(TFRecordPath):\n",
    "    with tf.Session() as sess:\n",
    "        feature = {\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "            'person': tf.FixedLenFeature([], tf.int64),\n",
    "        }\n",
    "#         filename_queue = tf.train.string_input_producer([TFRecordPath], num_epochs = 1)\n",
    "        filename_queue = tf.train.string_input_producer([TFRecordPath])\n",
    "        reader = tf.TFRecordReader()\n",
    "        _, serialized_example = reader.read(filename_queue)\n",
    "        features = tf.parse_single_example(serialized_example, features = feature)\n",
    "        image = tf.decode_raw(features['image'], np.float64)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image = tf.reshape(image, [31, 128, 128, 1])\n",
    "        label = tf.cast(features['label'], tf.int32)\n",
    "        return image, label - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s 步长，channels_in 输入通道，channels_out 输出通道\n",
    "def conv3d_layer(X, k, s, channels_in, channels_out, is_training, name = 'CONV'):\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.Variable(tf.truncated_normal([k, k, k, channels_in, channels_out], stddev = 0.1));\n",
    "        b = tf.Variable(tf.constant(0.1, shape = [channels_out]))\n",
    "        conv = tf.nn.conv3d(X, W, strides = [1, s, s, s, 1], padding = 'SAME') + b\n",
    "#         bn = tf.layers.batch_normalization(conv, training = is_training)\n",
    "        result = tf.nn.relu(conv)\n",
    "        tf.summary.histogram('weights', W)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        tf.summary.histogram('activations', result)\n",
    "        return result\n",
    "    \n",
    "def pool3d_layer(X, k, s, strr = 'SAME', pool_type = 'MAX', name = 'pool', down_stride = 1):\n",
    "    if pool_type == 'MAX':\n",
    "        result = tf.nn.max_pool3d(X,\n",
    "                              ksize = [1, down_stride, k, k, 1],\n",
    "                              strides = [1, down_stride, s, k, 1],\n",
    "                              padding = strr,\n",
    "                              name = name)\n",
    "    else:\n",
    "        result = tf.nn.avg_pool3d(X,\n",
    "                              ksize = [1, down_stride, k, k, 1],\n",
    "                              strides = [1, down_stride, s, k, 1],\n",
    "                              padding = strr,\n",
    "                              name = name)\n",
    "    return result\n",
    "\n",
    "def fc_layer(X, neurons_in, neurons_out, last = False, name = 'FC'):\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.Variable(tf.truncated_normal([neurons_in, neurons_out], stddev = 0.1))\n",
    "        b = tf.Variable(tf.constant(0.1, shape = [neurons_out]))\n",
    "        tf.summary.histogram('weights', W)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        if last == False:\n",
    "            result = tf.nn.relu(tf.matmul(X, W) + b)\n",
    "        else:\n",
    "            result = tf.matmul(X, W) + b\n",
    "        tf.summary.histogram('activations', result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Network(BatchSize, learning_rate):\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        is_training = tf.placeholder(dtype = tf.bool, shape=())\n",
    "        keep_prob = tf.placeholder('float32', name = 'keep_prob')\n",
    "        \n",
    "        judge = tf.Print(is_training, ['is_training:', is_training])\n",
    "        \n",
    "        image_train, label_train = read_tfrecord(trainPath) \n",
    "        image_val, label_val = read_tfrecord(valPath) \n",
    "\n",
    "        image_train_Batch, label_train_Batch = tf.train.shuffle_batch([image_train, label_train], \n",
    "                                                     batch_size = BatchSize, \n",
    "                                                     capacity = BatchSize*3 + 200,\n",
    "                                                     min_after_dequeue = BatchSize)\n",
    "        image_val_Batch, label_val_Batch = tf.train.shuffle_batch([image_val, label_val], \n",
    "                                                     batch_size = BatchSize, \n",
    "                                                     capacity = BatchSize*3 + 200,\n",
    "                                                     min_after_dequeue = BatchSize)\n",
    "        \n",
    "        image_Batch = tf.cond(is_training, lambda: image_train_Batch, lambda: image_val_Batch)\n",
    "        label_Batch = tf.cond(is_training, lambda: label_train_Batch, lambda: label_val_Batch)\n",
    "        \n",
    "        label_Batch = tf.one_hot(label_Batch, depth = 3)\n",
    "        \n",
    "\n",
    "\n",
    "        X = tf.identity(image_Batch)\n",
    "        y = tf.identity(label_Batch)\n",
    "    \n",
    "        conv1_1 = conv3d_layer(X, 3, 1, 1, 16, is_training, \"conv1_1\")\n",
    "        conv1_2 = conv3d_layer(conv1_1, 3, 1, 16, 16, is_training, \"conv1_2\")\n",
    "#         conv1_3 = conv3d_layer(conv1_2, 3, 1, 16, 16, is_training, \"conv1_3\")\n",
    "        pool1 = pool3d_layer(conv1_2, 2, 2, \"SAME\", \"MAX\", 'pool1')\n",
    "\n",
    "        conv2_1 = conv3d_layer(pool1, 3, 1, 16, 32, is_training, 'conv2_1')\n",
    "#         conv2_2 = conv3d_layer(conv2_1, 3, 1, 32, 32, is_training, 'conv2_2')\n",
    "        pool2 = pool3d_layer(conv2_1, 2, 2, \"SAME\", \"MAX\", 'pool2')\n",
    "        \n",
    "        conv3 = conv3d_layer(pool2, 3, 1, 32, 16, is_training, 'conv3')\n",
    "        pool3 = pool3d_layer(conv3, 2, 2, \"SAME\", \"MAX\", 'pool3', down_stride = 2)\n",
    "        print(pool3.shape)\n",
    "        \n",
    "        drop1 = tf.nn.dropout(pool3, keep_prob)\n",
    "        fc1 = fc_layer(tf.reshape(drop1, [-1, 16 * 16 * 16 * 16]), 16 * 16 * 16 * 16, 1024, name = 'fc1')\n",
    "        \n",
    "        drop2 = tf.nn.dropout(fc1, keep_prob)\n",
    "        fc2 = fc_layer(drop2, 1024, 128, name = 'fc2')\n",
    "        \n",
    "        drop3 = tf.nn.dropout(fc2, keep_prob)\n",
    "        y_result = fc_layer(drop3, 128, 3, True, name = 'fc3')\n",
    "        \n",
    "        \n",
    "#         conv4 = conv3d_layer(pool3, 3, 1, 38, 3, 'conv4')\n",
    "#         pool4 = pool3d_layer(conv4, 11, 11, \"SAME\", \"MEAN\", 'pool4')\n",
    "#         print(pool4.shape)\n",
    "        \n",
    "#         y_result = tf.reshape(pool4, [-1, 3])\n",
    "#         print(y_result.shape)\n",
    "        \n",
    "        with tf.name_scope('summaries'):\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops): \n",
    "    #             cross_entropy = -tf.reduce_mean(y * tf.log(tf.clip_by_value(y_result, 1e-10,1.0)))\n",
    "                cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_result, labels = y))\n",
    "                train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "                #train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "                corrent_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_result, 1))\n",
    "                accuracy = tf.reduce_mean(tf.cast(corrent_prediction, 'float', name = 'accuracy'))\n",
    "                tf.summary.scalar(\"loss\", cross_entropy)\n",
    "                tf.summary.scalar(\"accuracy\", accuracy)\n",
    "            \n",
    "        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "        sess.run(init_op)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord = coord)\n",
    "        \n",
    "        merge_summary = tf.summary.merge_all()\n",
    "        summary__train_writer = tf.summary.FileWriter(\"./logs/train\" + '_rate:' + str(learning_rate) + '_' + str(BatchSize), sess.graph)\n",
    "        summary_val_writer = tf.summary.FileWriter(\"./logs/test\" + '_rate:' + str(learning_rate) + '_' + str(BatchSize))\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        can_save_model = False\n",
    "        try:\n",
    "            batch_index = 1\n",
    "            while not coord.should_stop():\n",
    "                sess.run([train_step], feed_dict = {keep_prob: 0.5, is_training: True})\n",
    "                if batch_index % 10 == 0:\n",
    "                    summary_train, _, acc_train, loss_train = sess.run([merge_summary, train_step, accuracy, cross_entropy], feed_dict = {keep_prob: 0.5, is_training: True})   \n",
    "                    summary__train_writer.add_summary(summary_train, batch_index) \n",
    "                    print(str(batch_index) + ' train:' + '  ' + str(acc_train) + ' ' + str(loss_train))\n",
    "                    summary_val, acc_val, loss_val = sess.run([merge_summary, accuracy, cross_entropy], feed_dict = {keep_prob: 1.0, is_training: False}) \n",
    "                    summary_val_writer.add_summary(summary_val, batch_index) \n",
    "                    print(str(batch_index) + '  val: ' + '  ' + str(acc_val) + ' ' + str(loss_val))\n",
    "\n",
    "                    if acc_val > 0.8 :\n",
    "                        can_save_model = True\n",
    "                    \n",
    "#                 if can_save_model == True and batch_index % 100 == 0:\n",
    "#                     save_path = saver.save(sess, model_path + 'Model__Step_{:04d}_{:d}_'.format(batch_index, BatchSize) + str(learning_rate))\n",
    "                \n",
    "#                 if can_save_model == False and batch_index % 1000 == 0:\n",
    "#                     break\n",
    "                    \n",
    "#                 if can_save_model == True and batch_index % 1500 == 0:\n",
    "#                     break\n",
    "#                 if batch_index % 1500 == 0:\n",
    "#                     break\n",
    "                if batch_index % 1000 == 0:\n",
    "                    save_path = saver.save(sess, model_path + 'Model__Step_{:04d}_{:d}_'.format(batch_index, BatchSize) + str(learning_rate))\n",
    "                batch_index += 1;\n",
    "                    \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"OutofRangeError!\")\n",
    "        finally:\n",
    "            print(\"Finish\")\n",
    "    \n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-4ec84d0fc357>:7: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-ecc632046bc8>:9: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/winsoul/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/winsoul/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/winsoul/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/winsoul/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/winsoul/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-ecc632046bc8>:10: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-5-4ec84d0fc357>:15: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n",
      "WARNING:tensorflow:From /home/winsoul/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(8, 16, 16, 16, 16)\n",
      "WARNING:tensorflow:From <ipython-input-5-4ec84d0fc357>:44: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-5-4ec84d0fc357>:65: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-5-4ec84d0fc357>:76: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "10 train:  0.25 51.459152\n",
      "10  val:   0.25 11.086243\n",
      "20 train:  0.125 34.394455\n",
      "20  val:   0.375 9.787675\n",
      "30 train:  0.5 4.9679275\n",
      "30  val:   0.375 2.5587926\n",
      "40 train:  0.25 6.1160293\n",
      "40  val:   0.125 1.6121898\n",
      "50 train:  0.25 4.840383\n",
      "50  val:   0.0 2.1827872\n",
      "60 train:  0.125 3.2584414\n",
      "60  val:   0.0 1.3498778\n",
      "70 train:  0.125 2.9891877\n",
      "70  val:   0.75 0.9448973\n",
      "80 train:  0.625 0.61919534\n",
      "80  val:   0.25 1.1644164\n",
      "90 train:  0.0 1.3875939\n",
      "90  val:   0.125 1.1441545\n",
      "100 train:  0.0 2.487866\n",
      "100  val:   0.0 1.2049853\n",
      "110 train:  0.25 1.7663152\n",
      "110  val:   0.625 1.0600436\n",
      "120 train:  0.375 1.3284228\n",
      "120  val:   0.0 1.1400481\n",
      "130 train:  0.0 1.7861116\n",
      "130  val:   0.25 1.129376\n",
      "140 train:  0.75 1.1598917\n",
      "140  val:   0.25 1.1233889\n",
      "150 train:  0.375 1.2646652\n",
      "150  val:   0.375 1.0973707\n",
      "160 train:  0.125 1.4576278\n",
      "160  val:   0.125 1.1478473\n",
      "170 train:  0.25 2.000939\n",
      "170  val:   0.25 1.11972\n",
      "180 train:  0.5 1.4803345\n",
      "180  val:   0.25 1.1699429\n",
      "190 train:  0.125 1.5179732\n",
      "190  val:   0.25 1.129662\n",
      "200 train:  0.25 1.3182925\n",
      "200  val:   0.375 1.126791\n",
      "210 train:  0.125 1.4863102\n",
      "210  val:   0.125 1.1074399\n",
      "220 train:  0.25 1.3601096\n",
      "220  val:   0.25 1.1446474\n",
      "230 train:  0.5 1.0723269\n",
      "230  val:   0.25 1.1020229\n",
      "240 train:  0.25 1.2371929\n",
      "240  val:   0.125 1.1202528\n",
      "250 train:  0.5 1.0971187\n",
      "250  val:   0.125 1.1204166\n",
      "260 train:  0.375 1.091763\n",
      "260  val:   0.125 1.1530182\n",
      "270 train:  0.5 0.9067011\n",
      "270  val:   0.125 1.164925\n",
      "280 train:  0.5 1.1410372\n",
      "280  val:   0.125 1.1351905\n",
      "290 train:  0.625 1.0014108\n",
      "290  val:   0.5 1.0580055\n",
      "300 train:  0.5 0.99332106\n",
      "300  val:   0.0 1.1584147\n",
      "310 train:  0.5 0.8281126\n",
      "310  val:   0.125 1.1227355\n",
      "320 train:  0.25 1.4145579\n",
      "320  val:   0.375 1.0930315\n",
      "330 train:  0.25 1.330471\n",
      "330  val:   0.375 1.1144524\n",
      "340 train:  0.125 1.3162769\n",
      "340  val:   0.375 1.1037815\n",
      "350 train:  0.125 1.2718449\n",
      "350  val:   0.5 1.0979489\n",
      "360 train:  0.25 1.0296228\n",
      "360  val:   0.375 1.1030831\n",
      "370 train:  0.5 1.010956\n",
      "370  val:   0.5 1.058136\n",
      "380 train:  0.5 0.96237147\n",
      "380  val:   0.25 1.1389458\n",
      "390 train:  0.25 1.1062368\n",
      "390  val:   0.25 1.1038908\n",
      "400 train:  0.375 1.1336117\n",
      "400  val:   0.5 1.0464298\n",
      "410 train:  0.375 1.0483785\n",
      "410  val:   0.5 1.0651116\n",
      "420 train:  0.75 0.894036\n",
      "420  val:   0.375 1.0918258\n",
      "430 train:  0.5 1.1031144\n",
      "430  val:   0.75 1.0307889\n",
      "440 train:  0.25 1.126966\n",
      "440  val:   0.25 1.0771635\n",
      "450 train:  0.375 1.0295484\n",
      "450  val:   0.625 1.0140293\n",
      "460 train:  0.25 1.2061357\n",
      "460  val:   0.75 0.9538928\n",
      "470 train:  0.5 0.92383766\n",
      "470  val:   0.625 0.9591496\n",
      "480 train:  0.375 1.0116171\n",
      "480  val:   0.375 1.0101106\n",
      "490 train:  0.625 0.92443794\n",
      "490  val:   0.625 1.0183632\n",
      "500 train:  0.375 1.0580457\n",
      "500  val:   0.375 1.0169095\n",
      "510 train:  0.5 0.8706492\n",
      "510  val:   0.5 1.0387385\n",
      "520 train:  0.5 1.027843\n",
      "520  val:   0.875 0.9177401\n",
      "530 train:  0.875 0.86110234\n",
      "530  val:   0.5 0.9789749\n",
      "540 train:  0.625 0.8898893\n",
      "540  val:   0.625 0.9316601\n",
      "550 train:  0.375 1.1027677\n",
      "550  val:   0.25 1.0131083\n",
      "560 train:  0.625 0.8546572\n",
      "560  val:   0.625 0.99094415\n",
      "570 train:  0.625 1.1507714\n",
      "570  val:   0.375 1.0942883\n",
      "580 train:  0.5 0.9583555\n",
      "580  val:   0.25 1.0068065\n",
      "590 train:  0.5 0.97379947\n",
      "590  val:   0.75 0.8825631\n",
      "600 train:  0.625 0.8897463\n",
      "600  val:   0.75 0.87635994\n",
      "610 train:  0.625 0.87399113\n",
      "610  val:   0.375 1.0880816\n",
      "620 train:  0.375 1.3409874\n",
      "620  val:   0.875 0.6403291\n",
      "630 train:  0.625 0.73355734\n",
      "630  val:   0.375 0.9392775\n",
      "640 train:  0.375 1.1396446\n",
      "640  val:   0.875 0.7925994\n",
      "650 train:  0.75 0.61474854\n",
      "650  val:   0.625 0.8132849\n",
      "660 train:  0.75 0.6812458\n",
      "660  val:   0.875 0.8622639\n",
      "670 train:  0.75 0.6422014\n",
      "670  val:   0.75 0.7455517\n",
      "680 train:  0.5 1.0177834\n",
      "680  val:   1.0 0.56993765\n",
      "690 train:  0.75 0.73713577\n",
      "690  val:   0.75 0.6780792\n",
      "700 train:  1.0 0.7191189\n",
      "700  val:   1.0 0.56454855\n",
      "710 train:  0.875 0.57418656\n",
      "710  val:   1.0 0.7550049\n",
      "720 train:  0.625 0.81287956\n",
      "720  val:   1.0 0.69507027\n",
      "730 train:  0.75 0.5880771\n",
      "730  val:   1.0 0.4541589\n",
      "740 train:  0.25 1.3198545\n",
      "740  val:   0.75 0.6159588\n",
      "750 train:  1.0 0.32749656\n",
      "750  val:   0.875 0.5964022\n",
      "760 train:  0.5 0.8887136\n",
      "760  val:   0.75 0.806914\n",
      "770 train:  0.875 0.6424237\n",
      "770  val:   1.0 0.5937423\n",
      "780 train:  0.625 0.90388346\n",
      "780  val:   0.875 0.45829338\n",
      "790 train:  1.0 0.20548998\n",
      "790  val:   0.625 0.5876275\n",
      "800 train:  0.75 0.69146705\n",
      "800  val:   1.0 0.36640072\n",
      "810 train:  0.75 0.47930706\n",
      "810  val:   0.875 0.36112028\n",
      "820 train:  0.875 0.56280005\n",
      "820  val:   1.0 0.49146858\n",
      "830 train:  0.75 0.51745075\n",
      "830  val:   1.0 0.32277128\n",
      "840 train:  0.75 0.42860493\n",
      "840  val:   1.0 0.2557301\n",
      "850 train:  1.0 0.3964513\n",
      "850  val:   1.0 0.18081886\n",
      "860 train:  0.875 0.43703464\n",
      "860  val:   1.0 0.33109406\n",
      "870 train:  1.0 0.39901453\n",
      "870  val:   0.875 0.29370323\n",
      "880 train:  0.875 0.4454428\n",
      "880  val:   1.0 0.41998312\n",
      "890 train:  0.625 1.0957745\n",
      "890  val:   1.0 0.2666976\n",
      "900 train:  0.75 0.5108737\n",
      "900  val:   1.0 0.12265432\n",
      "910 train:  0.75 0.54572594\n",
      "910  val:   1.0 0.1515317\n",
      "920 train:  0.875 0.2871461\n",
      "920  val:   1.0 0.08931714\n",
      "930 train:  0.75 0.41813505\n",
      "930  val:   1.0 0.139455\n",
      "940 train:  0.75 0.53529066\n",
      "940  val:   1.0 0.1849736\n",
      "950 train:  0.875 0.4892115\n",
      "950  val:   1.0 0.11622015\n",
      "960 train:  0.75 0.519167\n",
      "960  val:   1.0 0.09904321\n",
      "970 train:  0.875 0.5007384\n"
     ]
    }
   ],
   "source": [
    "#1, 12, 48, 24, 512, 0.003\n",
    "def main():\n",
    "    Network(8, 0.0003)\n",
    "#     rate = 0.01\n",
    "#     batch = 8\n",
    "#     while batch >= 1:\n",
    "#         rate = 0.01\n",
    "#         while rate > 0.00001:\n",
    "#             print(\"---------------------------------------------------------------------\")\n",
    "#             print(batch, rate)\n",
    "#             try:\n",
    "#                 Network(int(batch), rate)\n",
    "#             except KeyboardInterrupt:\n",
    "#                 pass\n",
    "#             rate /= 2\n",
    "#         batch /= 2\n",
    "\n",
    "#     print(\"---------------------------------------------------------------------\")\n",
    "# #     print(batch, rate)\n",
    "#     try:\n",
    "#         Network(16, 0.0003)\n",
    "#     except KeyboardInterrupt:\n",
    "#         pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
